import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

from pathlib import Path
from sklearn.decomposition import PCA
from statsmodels.tsa.stattools import acf

def save_current_plot(filename, save_dir):
    """Function that helps to save current graph."""
    if save_dir:
        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Path object ‡∏Å‡∏±‡∏ô‡πÄ‡∏´‡∏ô‡∏µ‡∏¢‡∏ß
        save_path = Path(save_dir) / filename
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"Saved: {save_path}")

def plot_loss_comparison(history_dict, save_dir=None):
    """‡∏û‡∏•‡πá‡∏≠‡∏ï‡∏Å‡∏£‡∏≤‡∏ü Loss ‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    plt.figure(figsize=(10, 6))
    for name, loss_data in history_dict.items():
        plt.plot(loss_data, label=name)
    
    plt.title("Training Loss Comparison")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    if save_dir:
        save_current_plot("loss_comparison.png", save_dir)
    
    plt.show()

def plot_time_series(x_real, x_fake, model_name, feature_idx=0, save_dir=None):
    plt.figure(figsize=(10, 5))
    plt.plot(x_real[0, :, feature_idx], label="Real", color="blue", alpha=0.7)
    plt.plot(x_fake[0, :, feature_idx], label="Synthetic", color="red", alpha=0.7)
    plt.title(f"Time Series: Real vs {model_name}")
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    if save_dir:
        save_current_plot(f"{model_name}_timeseries.png", save_dir)
    
    plt.show()

def plot_distribution(x_real, x_fake, model_name, feature_idx=0, save_dir=None):
    plt.figure(figsize=(10, 5))
    sns.kdeplot(x_real[:, :, feature_idx].flatten(), color="blue", label="Real", fill=True, alpha=0.3)
    sns.kdeplot(x_fake[:, :, feature_idx].flatten(), color="red", label="Synthetic", fill=True, alpha=0.3)
    plt.title(f"Distribution (KDE): Real vs {model_name}")
    plt.legend()
    
    if save_dir:
        save_current_plot(f"{model_name}_distribution.png", save_dir)
    
    plt.show()

def plot_pca(x_real, x_fake, model_name, save_dir=None):
    real_flat = x_real.reshape(x_real.shape[0], -1)
    fake_flat = x_fake.reshape(x_fake.shape[0], -1)
    
    pca = PCA(n_components=2)
    pca.fit(real_flat)
    r_pca = pca.transform(real_flat)
    f_pca = pca.transform(fake_flat)
    
    plt.figure(figsize=(8, 6))
    plt.scatter(r_pca[:, 0], r_pca[:, 1], label="Real", alpha=0.5, color="blue")
    plt.scatter(f_pca[:, 0], f_pca[:, 1], label="Synthetic", alpha=0.5, color="red")
    plt.title(f"PCA: Real vs {model_name}")
    plt.legend()
    
    if save_dir:
        save_current_plot(f"{model_name}_pca.png", save_dir)
    
    plt.show()

def _compute_avg_acf(data, steps=20, feature_idx=0):
    acfs = []
    for i in range(len(data)):
        try:
            stat = acf(data[i, :, feature_idx], nlags=steps, fft=True)
            acfs.append(stat)
        except:
            pass # if there have errors
    return np.mean(acfs, axis=0) if acfs else np.zeros(steps+1)

def plot_acf(x_real, x_fake, model_name, save_dir=None):
    real_acf = _compute_avg_acf(x_real)
    fake_acf = _compute_avg_acf(x_fake)
    
    plt.figure(figsize=(8, 4))
    plt.plot(real_acf, label="Real ACF", marker='o', color="blue")
    plt.plot(fake_acf, label="Synthetic ACF", marker='x', linestyle='--', color="red")
    plt.title(f"ACF: Real vs {model_name}")
    plt.legend()
    plt.grid(True)
    
    if save_dir:
        save_current_plot(f"{model_name}_acf.png", save_dir)
        
    plt.show()

def visualize_all(x_real, x_fake, model_name, save_dir=None):
    """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß Save ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏∏‡∏Å‡∏£‡∏π‡∏õ ‡πÇ‡∏î‡∏¢‡πÅ‡∏õ‡∏∞‡∏ä‡∏∑‡πà‡∏≠ Model ‡πÑ‡∏ß‡πâ‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå"""
    print(f"Visualizing & Saving for {model_name}...")
    
    plot_time_series(x_real, x_fake, model_name, save_dir=save_dir)
    plot_distribution(x_real, x_fake, model_name, save_dir=save_dir)
    plot_pca(x_real, x_fake, model_name, save_dir=save_dir)
    plot_acf(x_real, x_fake, model_name, save_dir=save_dir)


def plot_comparison(dataloader, model, diffusion, scaler, dataset, device="cuda"):
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Real vs Fake (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Dataset ‡πÅ‡∏ö‡∏ö Dictionary)
    """
    model.eval()
    
    # -------------------------------------------------------
    # 1. üì• ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á (Real)
    # -------------------------------------------------------
    # ‡∏î‡∏∂‡∏á‡∏°‡∏≤ 1 Batch
    batch = next(iter(dataloader)) 
    
    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö (x_raw) ‡∏°‡∏≤‡πÄ‡∏•‡∏¢! ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Inverse Transform ‡πÉ‡∏´‡πâ‡∏¢‡∏∏‡πà‡∏á‡∏¢‡∏≤‡∏Å
    # shape: [B, L, C] -> ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÅ‡∏£‡∏Å [0] -> [L, C]
    real_sample_raw = batch['x_raw'][0].cpu().numpy()

    # -------------------------------------------------------
    # 2. ü§ñ ‡πÄ‡∏™‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏•‡∏≠‡∏° (Fake)
    # -------------------------------------------------------
    print(f"Generating synthetic data...")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á 1 ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
    # fake_scaled shape: [1, L, C] (‡∏Ñ‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô -1 ‡∏ñ‡∏∂‡∏á 1)
    fake_scaled = diffusion.sample(model, n=1) 
    
    # ‡∏î‡∏∂‡∏á‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô numpy [L, C]
    fake_sample_scaled = fake_scaled[0].cpu().numpy()

    # -------------------------------------------------------
    # 3. üîÑ ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏•‡∏≠‡∏° (Inverse Scale)
    # -------------------------------------------------------
    
    # ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤ Scaler ‡∏ñ‡∏π‡∏Å Fit ‡∏°‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
    if scaler is not None:
        fake_sample_raw = scaler.inverse_transform(fake_sample_scaled)
    else:
        # ‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ Scale (scale=False) ‡∏Å‡πá‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏•‡∏¢
        fake_sample_raw = fake_sample_scaled

    # -------------------------------------------------------
    # 4. üìà ‡∏û‡∏•‡πá‡∏≠‡∏ï‡∏Å‡∏£‡∏≤‡∏ü (Dynamic Layout)
    # -------------------------------------------------------
    features = dataset.features # ["Open", "Close", ...]
    num_features = len(features)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Subplots ‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á
    fig, axs = plt.subplots(num_features, 1, figsize=(12, 4 * num_features), sharex=True)
    
    # ‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ Feature ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡πÄ‡∏ä‡πà‡∏ô‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏Ñ‡πà Close) ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á axs ‡πÄ‡∏õ‡πá‡∏ô list
    if num_features == 1:
        axs = [axs]

    for i, name in enumerate(features):
        ax = axs[i]
        
        # ‡∏Å‡∏£‡∏≤‡∏ü‡∏à‡∏£‡∏¥‡∏á (‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô) - ‡∏à‡∏≤‡∏Å x_raw
        ax.plot(real_sample_raw[:, i], label='Real Data (Raw)', color='dodgerblue', alpha=0.8, linewidth=2)
        
        # ‡∏Å‡∏£‡∏≤‡∏ü‡∏õ‡∏•‡∏≠‡∏° (‡∏™‡∏µ‡∏™‡πâ‡∏°‡πÅ‡∏î‡∏á) - ‡∏à‡∏≤‡∏Å AI Gen
        ax.plot(fake_sample_raw[:, i], label='AI Generated', color='orangered', linestyle='--', alpha=0.9, linewidth=2)
        
        ax.set_title(f"Feature: {name}", fontsize=12, fontweight='bold')
        ax.legend()
        ax.grid(True, linestyle=':', alpha=0.6)

    plt.tight_layout()
    plt.show()
    
    model.train() # ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡∏™‡∏±‡∏ö‡∏™‡∏ß‡∏¥‡∏ï‡∏ä‡πå‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô Train ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏ó‡∏£‡∏ô
